{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasminiSantos/TDE3-Apache-Spark-SQL/blob/main/TDE3_Apache_Spark_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRDugJDwk8zU",
        "outputId": "1a171c3d-e6c1-4511-c326-2899bcce9617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=5e4def85ce211e23fcd548f4ebcbc5baad5d21139b6020ee68cfe287a5a38561\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9Str360kKFE",
        "outputId": "cc3855ad-c302-4b91-a96e-f4d5b1f37617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-03 13:56:05--  https://jpbarddal.github.io/assets/data/bigdata/transactions_amostra.csv.zip\n",
            "Resolving jpbarddal.github.io (jpbarddal.github.io)... 185.199.108.153, 185.199.110.153, 185.199.111.153, ...\n",
            "Connecting to jpbarddal.github.io (jpbarddal.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47513871 (45M) [application/zip]\n",
            "Saving to: ‘transactions_amostra.csv.zip’\n",
            "\n",
            "transactions_amostr 100%[===================>]  45.31M   219MB/s    in 0.2s    \n",
            "\n",
            "2023-06-03 13:56:07 (219 MB/s) - ‘transactions_amostra.csv.zip’ saved [47513871/47513871]\n",
            "\n",
            "Archive:  transactions_amostra.csv.zip\n",
            "  inflating: transactions_amostra.csv  \n",
            "  inflating: __MACOSX/._transactions_amostra.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget https://jpbarddal.github.io/assets/data/bigdata/transactions_amostra.csv.zip\n",
        "!unzip transactions_amostra.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b94WpZgWkXze"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        ".master('local[*]')\\\n",
        ".appName('tde3').getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\"transactions_amostra.csv\", header=True, inferSchema=True, sep=\";\")\n",
        "\n",
        "df.createOrReplaceTempView(\"transactions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmkxqT8Bk-R8"
      },
      "outputs": [],
      "source": [
        "# ======= QUESTÃO 1 =======\n",
        "\n",
        "# CONTAR QUANTAS TRANSAÇÕES TEM O BRASIL ENVOLVIDO\n",
        "transacoesBrasil = spark.sql(\"SELECT COUNT(*) AS count FROM transactions WHERE country_or_area = 'Brazil'\")\n",
        "\n",
        "# BUSCA A QUANTIDADE\n",
        "contador = transacoesBrasil.first()[\"count\"]\n",
        "\n",
        "print(\"NÚMERO DE TRANSAÇÕES ENVOLVENDO O BRASIL:\", contador)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI1-DHdmlDKo"
      },
      "outputs": [],
      "source": [
        "# ======= QUESTÃO 2 =======\n",
        "\n",
        "# CALCULAR O NUMERO DE TRANSAÇÕES POR TIPO DE FLOW E ANO\n",
        "transacoesPorFlowAno = spark.sql(\"SELECT Flow, Year, COUNT(*) AS count FROM transactions GROUP BY Flow, Year\")\n",
        "\n",
        "# PRINTA OS RESULTADOS\n",
        "transacoesPorFlowAno.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QGOxGm1flGCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2694af-0ef7-4867-c4af-8c1881dab119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+\n",
            "|year|       average_value|\n",
            "+----+--------------------+\n",
            "|1990| 1.172426586778952E7|\n",
            "|2003|1.3028917611334749E7|\n",
            "|2007|2.3710673174875777E7|\n",
            "|2015|   3.1115574884196E7|\n",
            "|2006|2.1175872541099638E7|\n",
            "|2013| 3.306115128882995E7|\n",
            "|1997|   9549881.214776853|\n",
            "|1988| 1.864297055638571E7|\n",
            "|1994|1.1350325049077941E7|\n",
            "|2014| 4.612040441345007E7|\n",
            "|2004|1.5388487793083541E7|\n",
            "|1991| 1.306922385515173E7|\n",
            "|1996|1.1945524161286663E7|\n",
            "|1989|1.1263871329920229E7|\n",
            "|1998|1.0175610459598826E7|\n",
            "|2012|3.9028921881444596E7|\n",
            "|2009|2.5068409504465386E7|\n",
            "|2016| 2.941832757526777E7|\n",
            "|1995|1.2286454103356835E7|\n",
            "|2001|   9942220.288239626|\n",
            "+----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======= QUESTÃO 3 =======\n",
        "\n",
        "# CALCULANDO AS MÉDIAS DOS COMODITIES REFERENTE A CADA ANO\n",
        "mediaComoditiesPorAno = spark.sql(\"SELECT year, AVG(trade_usd) AS average_value FROM transactions GROUP BY year\")\n",
        "\n",
        "# PRINTA\n",
        "mediaComoditiesPorAno.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M5WT5Z7xlI6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450c4260-e382-4f3e-bb0c-4f0e01778e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+-------------------+\n",
            "|Year|            category|      average_price|\n",
            "+----+--------------------+-------------------+\n",
            "|2007|30_pharmaceutical...|            95057.0|\n",
            "|1993|27_mineral_fuels_...|          5313712.5|\n",
            "|2016|37_photographic_o...| 2319.6666666666665|\n",
            "|2000|     01_live_animals|          1952949.0|\n",
            "|1992|15_animal_vegetab...|          2108165.4|\n",
            "|2008|38_miscellaneous_...|       4.49661584E7|\n",
            "|2014|68_stone_plaster_...|          1.84138E7|\n",
            "|2006|27_mineral_fuels_...| 3407871.6666666665|\n",
            "|1993|28_inorganic_chem...|         4578559.24|\n",
            "|2008|28_inorganic_chem...|         4449268.25|\n",
            "|1994|39_plastics_and_a...| 3172772.5454545454|\n",
            "|2005|02_meat_and_edibl...|       2.09560584E8|\n",
            "|2007|48_paper_paperboa...|5.556047253333333E7|\n",
            "|1991|93_arms_and_ammun...|            69896.0|\n",
            "|1999|80_tin_and_articl...|        1.5815404E7|\n",
            "|1994|17_sugars_and_sug...|8.347317433333333E7|\n",
            "|1997|60_knitted_or_cro...|         3641387.75|\n",
            "|1999|22_beverages_spir...|          2038685.2|\n",
            "|1997|22_beverages_spir...|  663407.6666666666|\n",
            "|2007|35_albuminoids_mo...|        2.3422103E7|\n",
            "+----+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======= QUESTÃO 4 =======\n",
        "\n",
        "# CALCULA O PREÇO MÉDIO POR TIPO DE UNIDADE, ANO E CATEGORIA QUE SÃO DO TIPO EXPORTAÇÃO NO BRASIL\n",
        "# E AGRUPO POR ANO E CATEGORIA\n",
        "precoMedioPorUnidadeAnoCat = spark.sql(\"\"\"\n",
        "    SELECT Year, category, AVG(trade_usd) AS average_price\n",
        "    FROM transactions\n",
        "    WHERE Flow = 'Export' AND country_or_area = 'Brazil'\n",
        "    GROUP BY  Year, Category\n",
        "\"\"\")\n",
        "\n",
        "# PRINTA\n",
        "precoMedioPorUnidadeAnoCat.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TXozkrG8mlVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960af362-b008-4cec-f5c8-3701f2757397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+------------------+-----------+-----------+\n",
            "|Year|       quantity_name|        valorMedio|valorMaximo|valorMinimo|\n",
            "+----+--------------------+------------------+-----------+-----------+\n",
            "|2002|  Number of packages|             550.0|        550|        550|\n",
            "|2006|  Number of packages|            1268.0|       1268|       1268|\n",
            "|1991|Electrical energy...|            2515.0|       2515|       2515|\n",
            "|2016|    Length in metres|  74562.9512195122|     961206|         19|\n",
            "|2015|    Length in metres|116034.65909090909|    1631741|         13|\n",
            "|2012|  Number of packages| 144575.2857142857|     459884|       6961|\n",
            "|2003|  Thousands of items|          402348.0|    2428778|        721|\n",
            "|2004|  Number of packages|          436233.5|     815330|      57137|\n",
            "|2013|    Length in metres| 678828.8545454545|   26620892|         77|\n",
            "|2014|    Length in metres| 758637.3518518518|   18030313|         15|\n",
            "|1989|    Length in metres|1013384.7647058824|   27013051|        518|\n",
            "|2010|    Length in metres|         1055655.2|   27392879|         40|\n",
            "|2012|    Length in metres|1150099.1780821919|   21341487|         19|\n",
            "|2015|    Weight in carats|         1150406.0|    1766318|     106617|\n",
            "|2009|  Number of packages|         1217627.1|   10088839|        931|\n",
            "|1988|    Length in metres|1288585.4666666666|   12233952|       2220|\n",
            "|2011|    Length in metres|1343239.9888888889|   58172373|        228|\n",
            "|2014|    Weight in carats|1397241.1666666667|    8219261|         57|\n",
            "|1991|    Length in metres|1415063.2926829269|   12037989|         63|\n",
            "|2015|  Thousands of items|1831404.5454545454|    6045811|        233|\n",
            "+----+--------------------+------------------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======= QUESTÃO 5 =======\n",
        "\n",
        "# CALCULA O VALOR MÁXIMO, MÍNIMO E MÉDIA POR TIPO DE UNIDADE E ANO\n",
        "maxMinMedia = spark.sql(\"\"\"\n",
        "    SELECT Year, quantity_name, AVG(trade_usd) AS valorMedio, MAX(trade_usd) AS valorMaximo, MIN(trade_usd) AS valorMinimo\n",
        "    FROM transactions\n",
        "    GROUP BY Year, quantity_name\n",
        "    ORDER BY valorMedio, valorMaximo, valorMinimo\n",
        "\"\"\")\n",
        "\n",
        "maxMinMedia.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9w9YUp3QmoBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b56d753-bc29-47e0-eb91-f718a0a21003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------------+\n",
            "|country_or_area|           avg_price|\n",
            "+---------------+--------------------+\n",
            "|         Angola|1.636966606814285...|\n",
            "+---------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======= QUESTÃO 6 =======\n",
        "\n",
        "# PROCURA O PAÍS COM MAIOR MÉDIA E PRINTA SOMENTE O MAIOR\n",
        "paisComMaiorMedia = spark.sql(\"\"\"\n",
        "    SELECT country_or_area, AVG(trade_usd) AS avg_price\n",
        "    FROM transactions\n",
        "    WHERE Flow = 'Export'\n",
        "    GROUP BY country_or_area\n",
        "    ORDER BY avg_price DESC\n",
        "    LIMIT 1\n",
        "\"\"\")\n",
        "\n",
        "paisComMaiorMedia.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======= QUESTÃO 7 =======\n",
        "\n",
        "# ENCONTRA A MAIOR QUANTIDADE QUE APARECE O COMMODITIE EM CADA TIPO DE FLOW\n",
        "# E RETORNA O MAIOR EM CADA\n",
        "comoditieMaisComercializado = spark.sql(\"\"\"\n",
        "    SELECT Flow, MAX(total_amount) AS max_amount\n",
        "    FROM (\n",
        "        SELECT Flow, Commodity, SUM(quantity) AS total_amount\n",
        "        FROM transactions\n",
        "        WHERE Year = '2016' AND Flow IN ('Export', 'Import', 'Re-Export', 'Re-Import')\n",
        "        GROUP BY Flow, Commodity\n",
        "    ) temp\n",
        "    GROUP BY Flow\n",
        "\"\"\")\n",
        "comoditieMaisComercializado.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIqTeeTMoLnk",
        "outputId": "fc4474cd-cef7-4026-f883-b9b16da56d43"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------------+\n",
            "|     Flow|      max_amount|\n",
            "+---------+----------------+\n",
            "|   Import|2.58289373308E11|\n",
            "|   Export|3.79546246752E11|\n",
            "|Re-Export|      1.261968E9|\n",
            "|Re-Import|     3.8774873E7|\n",
            "+---------+----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}