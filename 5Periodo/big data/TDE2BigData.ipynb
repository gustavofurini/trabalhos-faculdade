{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41HyHFqASSBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e51fa3b-a5b3-4b21-99b0-32764a5b79ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=5bced0f6f73be84fa6d9879e0f77f2d02c68885c802a6750d87ac2936099702f\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://jpbarddal.github.io/assets/data/bigdata/transactions_amostra.csv.zip\n",
        "!unzip transactions_amostra.csv.zip"
      ],
      "metadata": {
        "id": "8MHyxovkXfsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef85ce8e-07be-450a-ac9b-6f4163b653de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-29 22:08:17--  https://jpbarddal.github.io/assets/data/bigdata/transactions_amostra.csv.zip\n",
            "Resolving jpbarddal.github.io (jpbarddal.github.io)... 185.199.109.153, 185.199.108.153, 185.199.111.153, ...\n",
            "Connecting to jpbarddal.github.io (jpbarddal.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47513871 (45M) [application/zip]\n",
            "Saving to: ‘transactions_amostra.csv.zip’\n",
            "\n",
            "transactions_amostr 100%[===================>]  45.31M   189MB/s    in 0.2s    \n",
            "\n",
            "2023-05-29 22:08:17 (189 MB/s) - ‘transactions_amostra.csv.zip’ saved [47513871/47513871]\n",
            "\n",
            "Archive:  transactions_amostra.csv.zip\n",
            "  inflating: transactions_amostra.csv  \n",
            "  inflating: __MACOSX/._transactions_amostra.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, Window\n",
        "from pyspark import SparkFiles\n",
        "#from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "fYoKGXUoToBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master('local').appName('tdeSpark').getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "AGSbWjX-Tsn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = sc.textFile(\"transactions_amostra.csv\")"
      ],
      "metadata": {
        "id": "XhlSi4j1T0I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.take(5)"
      ],
      "metadata": {
        "id": "sU2r84S9T-kJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144e0e53-248e-49e9-92af-ae6c544a04d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['country_or_area;year;comm_code;commodity;flow;trade_usd;weight_kg;quantity_name;quantity;category',\n",
              " 'Belgium;2016;920510;Brass-wind instruments;Export;571297;3966.0;Number of items;4135.0;92_musical_instruments_parts_and_accessories',\n",
              " 'Guatemala;2008;660200;Walking-sticks, seat-sticks, whips, etc.;Export;35022;5575.0;Number of items;10089.0;66_umbrellas_walking_sticks_seat_sticks_whips_etc',\n",
              " 'Barbados;2006;220210;Beverage waters, sweetened or flavoured;Re-Export;81058;44458.0;Volume in litres;24113.0;22_beverages_spirits_and_vinegar',\n",
              " 'Tunisia;2016;780411;Lead foil of a thickness <2mm;Import;4658;121.0;Weight in kilograms;121.0;78_lead_and_articles_thereof']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== QUESTÃO 1 ========\n",
        "\n",
        "# FILTRA AS TRNSAÇÕES ENVOLVENDO O BRASIL\n",
        "transacoesBrasil = df.filter(lambda linha: \"Brazil\" in linha)\n",
        "\n",
        "# CONVERTE PARA CHAVE\n",
        "chaveQuestao1 = transacoesBrasil.map(lambda linha: (\"brazil\", 1))\n",
        "\n",
        "# CALCULA O TOTAL DE TRANSAÇÕES\n",
        "totalDeTransacoesBrasil = chaveQuestao1.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "contador = totalDeTransacoesBrasil.collect()[0][1]\n",
        "print(contador)\n"
      ],
      "metadata": {
        "id": "kq8QN42iZrTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe8c57c3-050a-42f0-8023-585f313b0736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== QUESTÃO 2 ========\n",
        "\n",
        "# DEFINE A CHAVE NA COMBINAÇÃO DO TIPO DE FLOW E ANO, E JA FAZ O REDUCE SOMANDO O VALORES\n",
        "transacoesPorFlowTipoAno = df.map(lambda linha: ((linha.split(\";\")[4], linha.split(\";\")[1]), 1)).reduceByKey(lambda x, y: x + y)\n",
        "print(\"TIPO DE FLOW, ANO \\t TRANSAÇÕES\")\n",
        "\n",
        "# ITERA SOBRE OS VALORES E IMPRIME O TIPO DE FLOW, ANO E A QUANTIDADE\n",
        "for tipoAno, contador in transacoesPorFlowTipoAno.collect():\n",
        "    print( tipoAno, \"\\t\", contador)\n",
        "     "
      ],
      "metadata": {
        "id": "Rj92YBdKbmnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c34e42e0-4b25-4f02-f987-0fa490fec935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIPO DE FLOW, ANO \t TRANSAÇÕES\n",
            "('Import', '2013') \t 30689\n",
            "('Import', '2010') \t 31435\n",
            "('Import', '2003') \t 29997\n",
            "('Export', '2015') \t 17756\n",
            "('Export', '2014') \t 17984\n",
            "('Import', '2012') \t 29987\n",
            "('Import', '2014') \t 29723\n",
            "('Import', '1995') \t 19375\n",
            "('Export', '2012') \t 17863\n",
            "('Export', '2013') \t 18063\n",
            "('Re-Export', '2003') \t 1706\n",
            "('Re-Export', '2013') \t 2225\n",
            "('Re-Import', '2005') \t 1323\n",
            "('Re-Export', '1995') \t 1132\n",
            "('Re-Export', '1990') \t 518\n",
            "('flow', 'year') \t 1\n",
            "('Export', '2008') \t 17445\n",
            "('Import', '2008') \t 29883\n",
            "('Import', '2005') \t 31124\n",
            "('Export', '2009') \t 17825\n",
            "('Export', '1989') \t 3547\n",
            "('Re-Import', '2011') \t 1456\n",
            "('Re-Import', '2012') \t 1418\n",
            "('Re-Import', '2014') \t 1457\n",
            "('Re-Import', '2003') \t 1242\n",
            "('Re-Export', '1992') \t 764\n",
            "('Export', '2016') \t 15260\n",
            "('Export', '2011') \t 17706\n",
            "('Import', '1994') \t 15718\n",
            "('Export', '2004') \t 17944\n",
            "('Export', '2003') \t 17484\n",
            "('Import', '2015') \t 28834\n",
            "('Import', '1990') \t 4866\n",
            "('Export', '1993') \t 7766\n",
            "('Import', '2002') \t 28956\n",
            "('Export', '1994') \t 10262\n",
            "('Re-Export', '2002') \t 1554\n",
            "('Re-Export', '2011') \t 2411\n",
            "('Re-Export', '2014') \t 2806\n",
            "('Export', '2007') \t 17445\n",
            "('Export', '1995') \t 11547\n",
            "('Re-Import', '2006') \t 1501\n",
            "('Re-Export', '1994') \t 1079\n",
            "('Re-Export', '2007') \t 2316\n",
            "('Re-Import', '2000') \t 952\n",
            "('Re-Export', '2015') \t 2646\n",
            "('Re-Import', '2001') \t 1001\n",
            "('Export', '1996') \t 12732\n",
            "('Import', '1998') \t 24881\n",
            "('Import', '2009') \t 31001\n",
            "('Import', '1997') \t 23685\n",
            "('Import', '2001') \t 29242\n",
            "('Export', '1997') \t 13541\n",
            "('Import', '1999') \t 26147\n",
            "('Import', '2006') \t 32301\n",
            "('Export', '2006') \t 18585\n",
            "('Re-Export', '2000') \t 2104\n",
            "('Import', '1988') \t 2139\n",
            "('Re-Import', '2004') \t 1197\n",
            "('Re-Export', '2009') \t 2528\n",
            "('Re-Import', '2002') \t 1119\n",
            "('Re-Import', '2013') \t 1431\n",
            "('Re-Import', '2015') \t 1479\n",
            "('Re-Export', '1998') \t 1519\n",
            "('Re-Import', '2010') \t 1278\n",
            "('Re-Export', '2001') \t 1874\n",
            "('Re-Export', '2008') \t 2323\n",
            "('Re-Export', '1988') \t 372\n",
            "('Re-Export', '1989') \t 482\n",
            "('Import', '2016') \t 22583\n",
            "('Export', '1991') \t 4499\n",
            "('Re-Import', '2009') \t 1385\n",
            "('Export', '2002') \t 16735\n",
            "('Import', '1993') \t 12140\n",
            "('Import', '2011') \t 31301\n",
            "('Import', '2004') \t 30945\n",
            "('Import', '2007') \t 31840\n",
            "('Export', '2010') \t 17849\n",
            "('Re-Import', '2008') \t 1366\n",
            "('Re-Export', '2016') \t 2298\n",
            "('Re-Export', '2004') \t 1877\n",
            "('Re-Export', '2010') \t 2348\n",
            "('Import', '1991') \t 6185\n",
            "('Export', '1990') \t 3700\n",
            "('Re-Export', '2012') \t 2345\n",
            "('Re-Export', '1993') \t 973\n",
            "('Re-Export', '1991') \t 652\n",
            "('Re-Export', '2006') \t 2431\n",
            "('Export', '1998') \t 14131\n",
            "('Export', '2005') \t 17993\n",
            "('Import', '1996') \t 21311\n",
            "('Export', '2000') \t 16855\n",
            "('Import', '1992') \t 9305\n",
            "('Export', '2001') \t 16759\n",
            "('Export', '1992') \t 6226\n",
            "('Re-Export', '1997') \t 1605\n",
            "('Export', '1988') \t 1772\n",
            "('Import', '1989') \t 4370\n",
            "('Import', '2000') \t 28884\n",
            "('Export', '1999') \t 15018\n",
            "('Re-Export', '1999') \t 2046\n",
            "('Re-Import', '2016') \t 939\n",
            "('Re-Export', '2005') \t 2379\n",
            "('Re-Import', '2007') \t 1328\n",
            "('Re-Export', '1996') \t 1211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== QUESTÃO 3 ========\n",
        "\n",
        " # FILTRA O VALOR DAS TRANSAÇÕES E O ANO E TIRA OS PONTOS PRESENTES\n",
        "valorCommodities = df.filter(lambda linha: linha.split(\";\")[5].replace(\".\", \"\").isdigit()).map(lambda linha: (linha.split(\";\")[1], float(linha.split(\";\")[5])))\n",
        "\n",
        "# AGREGAS OS VALORES DAS COMODITEIS POR ANO EM UMA TUPLA COM A SOMA TOTAL E QUANTIDADE DE OCORRÊNCIAS\n",
        "valorCommoditiesPorAno = valorCommodities.aggregateByKey((0.0, 0),\n",
        "                                                                  lambda x, y: (x[0] + y, x[1] + 1),\n",
        "                                                                  lambda a, b: (a[0] + b[0], a[1] + b[1]))\n",
        "\n",
        "# FAZ A MÉDIA\n",
        "mediaPorAno = valorCommoditiesPorAno.mapValues(lambda x: x[0] / x[1])\n",
        "\n",
        "# PRINTA O ANO E VALOR MÉDIO\n",
        "print(\"ANO \\t VALOR MÉDIO\")\n",
        "for ano, valorMedio in mediaPorAno.collect():\n",
        "    print(ano, \"\\t\", valorMedio)"
      ],
      "metadata": {
        "id": "XSHF3ZkHfa2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed2d7a4-ed9c-44f0-8b8e-4c776048e56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANO \t VALOR MÉDIO\n",
            "2016 \t 29418327.57526777\n",
            "2011 \t 33559943.50890797\n",
            "2003 \t 13028917.611334749\n",
            "1993 \t 10353959.855309162\n",
            "2007 \t 23710673.174875777\n",
            "2014 \t 46120404.41345007\n",
            "2012 \t 39028921.881444596\n",
            "1995 \t 12286454.103356835\n",
            "2006 \t 21175872.541099638\n",
            "1997 \t 9549881.214776853\n",
            "2005 \t 18673099.052178193\n",
            "1999 \t 9561516.927263891\n",
            "1992 \t 9402960.863025468\n",
            "1994 \t 11350325.049077941\n",
            "2004 \t 15388487.793083541\n",
            "1991 \t 13069223.85515173\n",
            "2002 \t 12653310.252481185\n",
            "2008 \t 33285215.353921242\n",
            "2001 \t 9942220.288239626\n",
            "2013 \t 33061151.28882995\n",
            "2010 \t 26909386.074333776\n",
            "2015 \t 31115574.884196\n",
            "1990 \t 11724265.86778952\n",
            "1996 \t 11945524.161286663\n",
            "1998 \t 10175610.459598826\n",
            "2009 \t 25068409.504465386\n",
            "2000 \t 13547613.067035558\n",
            "1988 \t 18642970.55638571\n",
            "1989 \t 11263871.329920229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== QUESTÃO 4 ========\n",
        "\n",
        "# FILTRA AS LINHAS CUJO O PAIS SEJA O BRASIL E O TIPO DE FLOW SEJA A EXPORTAÇÃO\n",
        "exportBrasil = df.filter(lambda x: \"Brazil\" in x and x.split(';')[4] == \"Export\")\n",
        "\n",
        "# CRIA A CHAVE QUE POSSUI OS VALORES DE ANO, TIPO DE UNIDADE, COMODITIE E QUANTIDADE\n",
        "precoPorTipoDeUnidade = exportBrasil.map(lambda x: ((x.split(';')[1], x.split(';')[7], x.split(';')[3], x.split(';')[8]), float(x.split(';')[5])))\n",
        "\n",
        "# AGREGA E FAZ A SOMA DE TODOS QUE POSSUEM O MESMO VALORES\n",
        "soma = precoPorTipoDeUnidade.aggregateByKey((0.0, 0), lambda x,y: (x[0] + y, x[1] + 1), lambda x,y: (x[0] + y[0], x[1] + y[1]))\n",
        "\n",
        "# CALCULA A MÉDIA\n",
        "valorMedio = soma.mapValues(lambda x: x[0]/x[1])\n",
        "\n",
        "# ITERA E PRINTA AS 5 PRIMEIRAS LINHAS\n",
        "print(\"ANO \\t   TIPO UNIDADE \\t\\t\\t    COMMODITIE \\t QUANTIDADE \\t VALOR MÉDIO\")\n",
        "contador = 0\n",
        "for media in valorMedio.collect():\n",
        "    if contador < 5:\n",
        "        print(media)\n",
        "        contador += 1\n",
        "    else:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "TttT9QOdmD3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ulZ1_c79i9_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== QUESTÃO 5 ========\n",
        "\n",
        "# FILTRANDO A BASE DE DADOS PELO TIPO DE UNIDADE, ANO E PRECO (MIN, MAX E MEDIA)\n",
        "transacoes = df.map(lambda linha: ((linha.split(\";\")[7], linha.split(\";\")[1]),\n",
        "                                   (float(linha.split(\";\")[5]), float(linha.split(\";\")[5]), float(linha.split(\";\")[5]), 1) if linha.split(\";\")[5].isdigit() else (0.0, 0.0, 0.0, 0.0)))\n",
        "\n",
        "# ENCONTRANDO MINIMO, O MAXIMO, SOMA DO PRECOS E A SOMA DAS QUANTIDADES\n",
        "somas = transacoes.reduceByKey(lambda x, y: (min(x[0], y[0]), max(x[1], y[1]), x[2] + y[2], x[3] + y[3]))\n",
        "\n",
        "# MAPEANDO A BASE DE DADOS E ENCONTRANDO O MIN E MAX E FAZENDO A MEDIA\n",
        "mediaPorTipoAno = somas.mapValues(lambda v: (v[0], v[1], v[2] / v[3]))\n",
        "mediaPorTipoAno.take(5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S_-FVuKfplKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== QUESTÃO 6 ========\n",
        "\n",
        "# FILTRA A BASE DE DADOS QUANDO O TIPO DE FLOW FOR A EXPORTAÇÃO\n",
        "export = df.filter(lambda linha: linha.split(\";\")[4] == \"Export\")\n",
        "\n",
        "# MAPEIA CADA LINHA REFERENTE A CHAVE PAÍS E VALOR DO COMODITIE\n",
        "precoPorPais = export.map(lambda linha: (linha.split(\";\")[0], float(linha.split(\";\")[5])))\n",
        "\n",
        "# FAZ A SOMA E CALCULA OS VALORES PARA CADA PAÍS\n",
        "soma = precoPorPais.aggregateByKey(\n",
        "    (0.0, 0),\n",
        "    lambda x, y: (x[0] + y, x[1] + 1),\n",
        "    lambda x1, x2: (x1[0] + x2[0], x1[1] + x2[1])\n",
        ")\n",
        "\n",
        "# CALCULA O VALOR MÉDIO PARA CADA PAÍS\n",
        "mediaPorPais = soma.mapValues(lambda x: x[0] / x[1])\n",
        "\n",
        "# PROCURA O PAÍS COM MAIS MÉDIA\n",
        "paisMaiorMedia = mediaPorPais.max(lambda a: a[1])\n",
        "\n",
        "# IMPRIME UM ÚNICO PAÍS NO OUTPUT\n",
        "print(\"PAÍS COM MAIOR MÉDIA NO TIPO EXPORT \\n\", paisMaiorMedia[0], paisMaiorMedia[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_JcNaqGd6TD",
        "outputId": "c2780d35-efa2-4106-9348-f674f7ddd306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "País com o maior preço médio de commodities na categoria Exportação \n",
            " Angola 16369666068.142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== QUESTÃO 7 ========\n",
        "# FILTRA AS LINHAS PARA AQUELAS QUE SÃO DO ANO DE 2016\n",
        "ano = df.filter(lambda linha: linha.split(';')[1] == \"2016\")\n",
        "\n",
        "# MAPEIA CADA LINHA, ONDE A CHAVE É O COMMODITIE E SEU VALOR É UMA TUPLA DO TIPO DE FLOW E QUANTIDADE\n",
        "comoditieTipoQuantidade = ano.map(lambda linha: (linha.split(';')[3], (linha.split(';')[4], float(linha.split(';')[8]))))\n",
        "\n",
        "# FILTRA AS LINHAS QUE SÃO DO TIPO RE-EXPORT\n",
        "reExport = comoditieTipoQuantidade.filter(lambda x: x[1][0] == \"Re-Export\")\n",
        "reExport = reExport.map(lambda x: (x[0], x[1][1]))\n",
        "# FAZ A SOMA\n",
        "somaReExport = reExport.reduceByKey(lambda x,y: x+y)\n",
        "# PEGA O VALOR MÁXIMO DE COMODITIES\n",
        "maxReExport = somaReExport.max(lambda x: x[1])\n",
        "\n",
        "# FILTRA AS LINHA QUE SÃO DO TIPO RE-IMPORT\n",
        "reImport = comoditieTipoQuantidade.filter(lambda x: x[1][0] == \"Re-Import\")\n",
        "reImport = reImport.map(lambda x: (x[0], x[1][1]))\n",
        "# FAZ A SOMA\n",
        "somaReImport = reImport.reduceByKey(lambda x,y: x + y)\n",
        "# PEGA O VALOR MÁXIMO DE COMODITIES\n",
        "maxReImport = somaReImport.max(lambda x: x[1])\n",
        "\n",
        "# FILTRA AS LINHAS QUE SÃO DO TIPO EXPORT\n",
        "export = comoditieTipoQuantidade.filter(lambda x: x[1][0] == \"Export\")\n",
        "export = export.map(lambda x: (x[0], x[1][1]))\n",
        "# FAZ A SOMA\n",
        "somaExport = export.reduceByKey(lambda x,y: x+y)\n",
        "# PEGA O VALOR MÁXIMO DE COMODITIES\n",
        "maxExport = somaExport.max(lambda x: x[1])\n",
        "\n",
        "# FILTRA AS LINHAS QUE SÃO DO TIPO IMPORT\n",
        "importt = comoditieTipoQuantidade.filter(lambda x: x[1][0] == \"Import\")\n",
        "importt = importt.map(lambda x: (x[0], x[1][1]))\n",
        "# FAZ A SOMA\n",
        "somaImport = importt.reduceByKey(lambda x,y: x+y)\n",
        "# PEGA O VALOR MÁXIMO DE COMODITIES\n",
        "maxImport = somaImport.max(lambda x: x[1])\n",
        "\n",
        "#PRINTA O TIPO DE FLOW, O COMMODITIE MAIS COMERCIALIZADO E A QUANTIDADE\n",
        "print(\"FLOW \\t   QUANTIDADE\")\n",
        "print(\"Re-Export:\", maxReExport)\n",
        "print(\"Re-Import:\", maxReImport)\n",
        "print(\"Export:\", maxExport)\n",
        "print(\"Import:\", maxImport)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug2RyaRbExVF",
        "outputId": "d9653f70-43cf-4290-9a0b-95be5d09210a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOW \t   QUANTIDADE\n",
            "Re-Export: ('Safety razor blades, including blanks in strips', 1261968000.0)\n",
            "Re-Import: ('Chem wood pulp, soda/sulphate, non-conifer, bleached', 38774873.0)\n",
            "Export: ('Iron ore, concentrate, not iron pyrites,unagglomerate', 379546246752.0)\n",
            "Import: ('Petroleum oils, oils from bituminous minerals, crude', 258289373308.0)\n"
          ]
        }
      ]
    }
  ]
}