{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ===== NAIVE BAYES COM SCIKIT LEARN =====\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Carregar a base de dados\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Dividir a base de dados em conjuntos de treino e teste usando holdout\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Treinar o classificador Naive Bayes\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar o desempenho do classificador\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Acurácia: {:.2f}%'.format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChBorPQKJ5Qr",
        "outputId": "01a9a668-3b5c-4cc4-a631-913254156fdb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 97.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== NAIVE BAYES SEM SCIKIT LEARN =====\n",
        "\n",
        "import csv\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "class NaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.mean = None\n",
        "        self.stdev = None\n",
        "        self.priors = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        n_samples, n_features = X_train.shape\n",
        "        self.classes = np.unique(y_train)\n",
        "        n_classes = len(self.classes)\n",
        "\n",
        "        # Calcula a média, desvio padrão e prior para cada classe\n",
        "        self.mean = np.zeros((n_classes, n_features))\n",
        "        self.stdev = np.zeros((n_classes, n_features))\n",
        "        self.priors = np.zeros(n_classes)\n",
        "        for i, c in enumerate(self.classes):\n",
        "            X_class = X_train[y_train == c]\n",
        "            self.mean[i, :] = X_class.mean(axis=0)\n",
        "            self.stdev[i, :] = X_class.std(axis=0)\n",
        "            self.priors[i] = X_class.shape[0] / float(n_samples)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        # Calcula a probabilidade para cada classe\n",
        "        posteriors = []\n",
        "        for i, c in enumerate(self.classes):\n",
        "            prior = np.log(self.priors[i])\n",
        "            likelihood = np.sum(np.log(self._gaussian_pdf(X_test, self.mean[i, :], self.stdev[i, :])), axis=1)\n",
        "            posterior = prior + likelihood\n",
        "            posteriors.append(posterior)\n",
        "\n",
        "        # Retorna a classe com a maior probabilidade\n",
        "        return np.argmax(posteriors, axis=0)\n",
        "\n",
        "    def _gaussian_pdf(self, X, mean, stdev):\n",
        "        exponent = np.exp(-((X - mean)**2 / (2 * stdev**2)))\n",
        "        return (1 / (np.sqrt(2 * np.pi) * stdev)) * exponent\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Divide os dados em conjuntos de treino e teste\n",
        "\n",
        "n_samples = X.shape[0]\n",
        "train_size = int(n_samples * 0.8)\n",
        "indices = list(range(n_samples))\n",
        "random.shuffle(indices)\n",
        "train_indices = indices[:train_size]\n",
        "test_indices = indices[train_size:]\n",
        "X_train = X[train_indices, :]\n",
        "y_train = y[train_indices]\n",
        "X_test = X[test_indices, :]\n",
        "y_test = y[test_indices]\n",
        "\n",
        "# Treina o classificador Naive Bayes\n",
        "clf = NaiveBayes()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Faz predições para os dados de teste\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calcula a acurácia do classificador\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print('Acurácia: {:.2f}%'.format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydYCn1Y-ViM8",
        "outputId": "c3a9ea31-5940-400c-be32-6771803394ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 92.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gu0DsQaHSGAJ"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}